# Ollama Configuration - REQUIRED
# Ollama API endpoint (make sure Ollama is running)
OLLAMA_BASE_URL=http://localhost:11434
# Model name - common options: mistral, neural-chat, llama2, zephyr
OLLAMA_MODEL=mistral
OLLAMA_TEMPERATURE=0.7
OLLAMA_MAX_TOKENS=150

# Speech Recognition Settings
SPEECH_LANGUAGE=en-US
SPEECH_TIMEOUT=10

# Text-to-Speech Settings
TTS_VOICE_RATE=150
TTS_VOICE_VOLUME=1.0
